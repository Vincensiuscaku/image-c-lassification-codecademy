{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "print(\"\\nLoading training data...\")\n",
        "\n",
        "training_data_generator = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05)\n",
        "\n",
        "training_iterator = training_data_generator.flow_from_directory('data/train',class_mode='categorical',color_mode='grayscale',batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "print(\"\\nLoading validation data...\")\n",
        "\n",
        "#1) Create validation_data_generator, an ImageDataGenerator that just performs pixel normalization:\n",
        "\n",
        "validation_data_generator = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "#1) Use validation_data_generator.flow_from_directory(...) to load the validation data from the 'data/test' folder:\n",
        "\n",
        "validation_iterator = validation_data_generator.flow_from_directory('data/test', class_mode='categorical', color_mode ='grayscale', batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "print(\"\\nBuilding model...\")\n",
        "\n",
        "#Rebuilds our model from the previous exercise, with convolutional and max pooling layers:\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=(256, 256, 1)))\n",
        "model.add(tf.keras.layers.Conv2D(2, 5, strides=3, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(5, 5), strides=(5,5)))\n",
        "model.add(tf.keras.layers.Conv2D(4, 3, strides=1, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2,2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(2,activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "print(\"\\nCompiling model...\")\n",
        "\n",
        "#2) Compile the model with an Adam optimizer, Categorical Cross Entropy Loss, and Accuracy and AUC metrics:\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.005),\n",
        "    loss = tf.keras.losses.categoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.AUC()]\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nTraining model...\")\n",
        "\n",
        "#3) Use model.fit(...) to train and validate our model for 5 epochs:\n",
        "\n",
        "model.fit(\n",
        "        training_iterator,\n",
        "        steps_per_epoch=training_iterator.samples/BATCH_SIZE,\n",
        "        epochs=5,\n",
        "        validation_data=valdiation_iterator,\n",
        "        validation_steps=validation_iterator.samples/BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "DN41JwtkH47h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}